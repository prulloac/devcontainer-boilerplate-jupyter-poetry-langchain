{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic test of the openai library\n",
    "\n",
    "The first snippet executes a sample prompt to openai directly using their library.\n",
    "\n",
    "Here we tell the model to act as if it were a poetic assistant with programming knowledge. Then we ask it to write a poem about recursion. The model then generates a poem about recursion in programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code, a curious thing,\n",
      "A pattern where function within does spring.\n",
      "Recursion, it's called, a loop unbound,\n",
      "The art of repeating without hitting the ground.\n",
      "\n",
      "Invoke it once, and then again,\n",
      "A function calls itself, an endless chain.\n",
      "Through problems complex, it weaves and winds,\n",
      "Solutions in its labyrinthine binds.\n",
      "\n",
      "A base case first, so crucial, so needful,\n",
      "To halt the cycle, lest it grows too heedful.\n",
      "For without this check, this vital break,\n",
      "An infinite loop our code will make.\n",
      "\n",
      "Like Russian dolls, one within the next,\n",
      "Functions unfold, their contents complex.\n",
      "Each layer peels to reveal one more,\n",
      "Till the smallest one shows the core.\n",
      "\n",
      "A fibonacci sequence, elegantly unfurled,\n",
      "Or traversing trees, roots to leaves unfurled.\n",
      "Recursion handles such tasks with grace,\n",
      "Processing each step, each recursive trace.\n",
      "\n",
      "Think of it as a spell, cast and recast,\n",
      "In an enchanter's chant, the magic is vast.\n",
      "But beware the charm, its seductive song,\n",
      "For without care, things may go wrong.\n",
      "\n",
      "A stack overflow, the dreaded plight,\n",
      "When memory's depths are filled with night.\n",
      "So mind your spells, your recursive call,\n",
      "With a base case end, to catch the fall.\n",
      "\n",
      "A poetic dance of logic, recursion stands,\n",
      "A paradox solved by your own hands.\n",
      "So wield it well, this tool profound,\n",
      "And let your code with recursion resound.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate test of the openai library, now with langchain\n",
    "\n",
    "This second snippet is a bit more sophisticated and uses langchain to execute a prompt.\n",
    "\n",
    "Here we tell the model to write a summary given a specific topic (again, recursion). The model then generates a summary about the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursion in programming is a method where a function calls itself directly or indirectly to solve a problem. It's a powerful tool that simplifies the code for tasks that can be broken down into similar subtasks. Recursion is often used in algorithms that deal with data structures like trees and graphs, as well as in sorting algorithms like quicksort and mergesort.\n",
      "\n",
      "A recursive function typically has two main components: the base case and the recursive case. The base case defines the condition under which the recursion will stop, preventing an infinite loop of function calls. The recursive case is where the function calls itself with a modified argument, gradually approaching the base case.\n",
      "\n",
      "For example, a classic instance of recursion is the calculation of factorial, where the factorial of a number n (denoted as n!) is the product of all positive integers less than or equal to n. The base case is when n equals 0 or 1, in which case the factorial is 1. The recursive case involves multiplying n by the factorial of n-1.\n",
      "\n",
      "Recursion can lead to elegant and clean solutions, but it also has its drawbacks. Each recursive call adds a new layer to the call stack, which can lead to stack overflow if the recursion is too deep. Additionally, recursion can be less efficient than iterative solutions due to the overhead of multiple function calls. To mitigate these issues, techniques like memoization or converting the recursive algorithm to an iterative one can be used.\n",
      "\n",
      "Understanding recursion requires a good grasp of function calls and the execution stack, as well as the ability to think in terms of dividing problems into smaller, more manageable parts. It's a fundamental concept in computer science and a valuable tool in a programmer's toolkit.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "summary_template = \"\"\"\n",
    "    given a topic {topic}, write a summary of the topic in your own words.\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(template=summary_template)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "print(chain.run(topic=\"recursion in programming\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complext test of the openai library, now with langchain and map-reduce\n",
    "\n",
    "The final snippet is the most sophisticated one.\n",
    "\n",
    "It first retrieves a list of news articles from google cloud blog RSS feed and load each article as a Human Readable text using nltk. Then it uses langchain to execute a map-reduce  algorithm which maps each article into a summary and then reduces them all to generate an output with the highlights of the google cloud blog latest news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update, here are some of the latest developments from Google Cloud:\n",
      "\n",
      "1. **Enhancements to Cybersecurity with ISACs**: Google Cloud has been actively supporting Information Sharing and Analysis Centers (ISACs) to improve cybersecurity across various sectors. By sharing threat intelligence, including strategies and methods used by attackers, organizations can respond more effectively to cyber threats. Google Cloud's partnership with Health-ISAC, for example, has led to an open-source integration that connects the Health-ISAC Indicator Threat Sharing (HITS) feed with Google's Chronicle Security Operations platform, allowing for rapid sharing and detection of cyber threats.\n",
      "\n",
      "2. **Investment in Cybersecurity**: Google has pledged to invest $10 billion over five years in cybersecurity advancements. This investment includes supporting ISACs and providing threat intelligence from Google services like Mandiant and VirusTotal to ISAC members at no extra cost.\n",
      "\n",
      "3. **Custom Queues for Compute Engine VMs**: Google Cloud introduced a new feature for Compute Engine VMs that allows users to assign custom queues per virtual network interface card (vNIC). This feature is designed to maximize network performance, especially for high-bandwidth applications, AI/ML workloads, and network virtual appliances. Users can now manually assign up to 32 network queues for virtIO and 16 for gVNIC without incurring additional costs.\n",
      "\n",
      "4. **Storage Options for GKE**: Google Kubernetes Engine (GKE) offers various storage options for applications, including local SSDs for high-performance needs, Persistent Disk for durable block storage, Cloud Storage buckets for object storage, and Filestore for centralized NFS storage. These options cater to different use cases and performance requirements, and customer experiences from companies like Weaviate, EnterpriseDB, and Elastic highlight the benefits of GKE's scalability and storage versatility.\n",
      "\n",
      "5. **Generative AI in Banking**: Google Cloud is exploring the potential of generative AI in the banking sector, focusing on enhancing banking services and customer experiences. The company emphasizes the need for responsible development and application of gen AI, addressing concerns about accuracy and security. Google Cloud outlines key areas for responsible gen AI integration in banking, including explainability, regulation, privacy, and security.\n",
      "\n",
      "6. **Generative AI in Financial Services**: Google Cloud has identified five key areas where generative AI can add value to capital markets firms, including customer onboarding, investment research, asset servicing, client engagement, and regulatory compliance. The technology is expected to enable financial institutions to better monitor portfolios, predict customer needs, and comply with regulations more efficiently.\n",
      "\n",
      "Please note that the information provided is based on the latest available data as of my knowledge cutoff date, and there may have been further developments or announcements from Google Cloud since then. For the most recent news and updates, you should check Google Cloud's official blog or press releases.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from functools import partial\n",
    "from langchain.chains.combine_documents import collapse_docs, split_list_of_docs\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import RSSFeedLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser, Document\n",
    "from langchain.schema.prompt_template import format_document\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "urls = [\"https://cloudblog.withgoogle.com/rss\"]\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0)\n",
    "\n",
    "loader = RSSFeedLoader(urls=urls, nlp=True)\n",
    "data = loader.load()\n",
    "\n",
    "document_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
    "partial_format_document = partial(format_document, prompt=document_prompt)\n",
    "\n",
    "map_chain = (\n",
    "    {\"context\": partial_format_document}\n",
    "    | PromptTemplate.from_template(\"Summarize this news article:\\n\\n{context}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "map_as_doc_chain = (\n",
    "    RunnableParallel({\"doc\": RunnablePassthrough(), \"content\": map_chain})\n",
    "    | (lambda x: Document(page_content=x[\"content\"], metadata=x[\"doc\"].metadata))\n",
    ").with_config(run_name=\"Summarize (return doc)\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(partial_format_document(doc) for doc in docs)\n",
    "\n",
    "collapse_chain = (\n",
    "    {\"context\": format_docs}\n",
    "    | PromptTemplate.from_template(\"Collapse this content:\\n\\n{context}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def get_num_tokens(docs):\n",
    "    return llm.get_num_tokens(format_docs(docs))\n",
    "\n",
    "def collapse(\n",
    "    docs,\n",
    "    config,\n",
    "    token_max=4000,\n",
    "):\n",
    "    collapse_ct = 1\n",
    "    while get_num_tokens(docs) > token_max:\n",
    "        config[\"run_name\"] = f\"Collapse {collapse_ct}\"\n",
    "        invoke = partial(collapse_chain.invoke, config=config)\n",
    "        split_docs = split_list_of_docs(docs, get_num_tokens, token_max)\n",
    "        docs = [collapse_docs(_docs, invoke) for _docs in split_docs]\n",
    "        collapse_ct += 1\n",
    "    return docs\n",
    "\n",
    "reduce_chain = (\n",
    "    {\"context\": format_docs}\n",
    "    | PromptTemplate.from_template(\"Based on these news summaries:\\n\\n{context}\\n\\n Tell me latest news from Google Cloud.\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ").with_config(run_name=\"Reduce\")\n",
    "\n",
    "map_reduce = (map_as_doc_chain.map() | collapse | reduce_chain).with_config(\n",
    "    run_name=\"Map reduce\"\n",
    ")\n",
    "\n",
    "print(map_reduce.invoke(data[0:5], config={\"max_concurrency\": 5}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
